#!/usr/bin/env python
# coding: utf-8

# 

# In[ ]:


import cv2
import matplotlib.pyplot as plt 


# In[ ]:


# gray to color conversion


# In[ ]:


path="./archive/dataset_9010/dataset_9010/malimg_dataset/train/Adialer.C/000bde2e9a94ba41c0c111ffd80647c2.png"
path2="./test_2.jpg"

image=cv2.imread(path,0)
color_image=cv2.imread(path2)

# image.shape
image.shape
color_image.shape

# plt.imshow(color_image)
plt.imshow(image,cmap='gray')

plt.imshow(color_image)


# In[5]:


import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator
import keras.applications.vgg16 as vgg16
import jovian
import keras
import numpy as np
import matplotlib.pyplot as plt


# 

# In[2]:


# reading train, validation and testing  dataset

train_data_path = r"D:\Nazish\Maleware_Detection\Color_Malimg Dataset\Color_malimg_dataset\train"
valid_data_path = r"D:\Nazish\Maleware_Detection\Color_Malimg Dataset\Color_malimg_dataset\validation"
test_data_path = r"D:\Nazish\Maleware_Detection\Color_Malimg Dataset\Color_malimg_dataset\test"

# train_set = ImageDataGenerator().flow_from_directory(directory=train_path, target_size=(224, 224), batch_size = 32)
# val_set = ImageDataGenerator().flow_from_directory(directory=val_path, target_size= (224, 224), batch_size = 32)
#test_set = ImageDataGenerator().flow_from_directory(directory=test_path, target_size= (224, 224), batch_size = 32)


train_set = ImageDataGenerator().flow_from_directory(train_data_path,
                                                    target_size=(224, 224),
                                                    batch_size=10000,
                                                    class_mode='categorical',shuffle=True)


val_set = ImageDataGenerator().flow_from_directory(val_data_path,
                                                        target_size=(224, 224),
                                                        batch_size=1000,
                                                        class_mode='categorical',shuffle=True)

test_set = ImageDataGenerator().flow_from_directory(test_data_path,
                                                        target_size=(224, 224),
                                                        batch_size=1000,
                                                        class_mode='categorical',shuffle=True)

# extracting image and labels from val and train set
val_imgs, val_labels = next(val_set)
train_imgs, train_labels = next(train_set)
test_imgs, train_labels = next(test_set)


# In[3]:


# classes of our dataset
train_set.class_indices


# In[6]:


# input image shape
images ,labesl= next(iter(train_set))
images.shape


# In[14]:


# pretrained VGG16 model without prediction head
conv_model = keras.applications.resnet.ResNet101(weights = "imagenet", include_top = False, input_shape=(224,224,3))

# Freezing parameters of features eaxtractor
conv_model.trainable = False

# feature extractor model summary
conv_model.summary()


# In[15]:


# flatten the output of the convolutional part:
x = keras.layers.Flatten()(conv_model.output)

# three hidden layers
x = keras.layers.Dense(500, activation='relu')(x)
x = keras.layers.Dense(50, activation = 'relu')(x)

# final softmax layer with 25 categories 
predictions = keras.layers.Dense(25, activation = 'softmax')(x)

# creating the full model
full_model = keras.models.Model(inputs = conv_model.input, outputs = predictions)

# feature extractor with prediction head model summary
full_model.summary()


# In[16]:


full_model.compile(loss='categorical_crossentropy',
                  optimizer=keras.optimizers.Adam(learning_rate=0.001),
                  metrics=['acc'])


# In[17]:


history = full_model.fit(
    train_set, 
    test_set,
    validation_data = val_set,
    epochs=25,
)


# In[21]:


conv_model = keras.applications.resnet.ResNet101(weights = "imagenet", include_top = False, input_shape=(224,224,3))

# Freezing parameters of features eaxtractor
conv_model.trainable = False

# feature extractor model summary
# conv_model.summary()
# flatten the output of the convolutional part:
x = keras.layers.Flatten()(conv_model.output)

# three hidden layers
x = keras.layers.Dense(1000, activation='relu')(x)
# x = keras.layers.Dense(50, activation = 'relu')(x)

# final softmax layer with 25 categories 
predictions = keras.layers.Dense(25, activation = 'softmax')(x)

# creating the full model
full_model = keras.models.Model(inputs = conv_model.input, outputs = predictions)

# feature extractor with prediction head model summary
# full_model.summary()
full_model.compile(loss='categorical_crossentropy',
                  optimizer=keras.optimizers.Adam(learning_rate=0.001),
                  metrics=['acc'])
history = full_model.fit(
    train_set, 
    test_set,
    validation_data = val_set,
    workers=5,
    epochs=20,
    batch_size=16
)


# In[18]:


# save the model
full_model.save(f'Saved_Models/vgg16_epoch_{10}_.h5')


# 

# In[20]:


hyperparams = {
    'arch_name': 'VGG16',
    'lr': .001
}
jovian.log_hyperparams(hyperparams)

metrics = {
    'epoch': 10,
    'train_loss': history.history['loss'][-1],
    'val_loss': history.history['val_loss'][-1],
    'Train_acc': history.history['acc'][-1],
    'val_acc': history.history['val_acc'][-1]
}


# In[ ]:





# # All_7_Pretrained_models

# In[17]:


# Defineing all models dictionary
pretrained_models = {
#                     "VGG16": keras.applications.vgg16.VGG16(weights="imagenet",include_top=False,input_shape=(224,224,3)),
#                     "VGG19": keras.applications.vgg19.VGG19(weights="imagenet",include_top=False,input_shape=(224,224,3)),
#                     "XCEPTION": keras.applications.xception.Xception(weights="imagenet",include_top=False,input_shape=(224,224,3)),
#                     "ResNet50": keras.applications.resnet.ResNet50(weights="imagenet",include_top=False,input_shape=(224,224,3)),
#                     "ResNet50v2": keras.applications.ResNet50V2(weights="imagenet",include_top=False,input_shape=(224,224,3)),
#                     "ResNet101": keras.applications.resnet.ResNet152(weights="imagenet",include_top=False,input_shape=(224,224,3)),
#                     "InceptionV3": keras.applications.inception_v3.InceptionV3(weights="imagenet",include_top=False,input_shape=(224,224,3)),
#                     "DenseNet121": keras.applications.densenet.DenseNet121(weights="imagenet",include_top=False,input_shape=(224,224,3)),
#                     "EfficientNetB0": keras.applications.efficientnet.EfficientNetB0(weights="imagenet",include_top=False,input_shape=(224,224,3))
}


# In[3]:


for model_key in pretrained_models.keys():
    conv_model = pretrained_models[f'{model_key}']
    
    # Freezing parameters of features eaxtractor
    conv_model.trainable = False
    
    # flatten the output of the convolutional part:
    x = keras.layers.Flatten()(conv_model.output)

    # three hidden layers
#     x = keras.layers.Dense(100, activation='relu')(x)
#     x1 = x
#     x = keras.layers.Dense(100, activation='relu')(x)
#     x2 = keras.layers.Dense(100)(x)
#     x3 = keras.layers.Add()([x1,x2])
    
#     x4 = keras.activations.relu(x3)
#     x = keras.layers.Dense(50, activation = 'relu')(x4)

    # final softmax layer with 25 categories 
    predictions = keras.layers.Dense(25, activation = 'softmax')(x)

    # creating the full model
    full_model = keras.models.Model(inputs = conv_model.input, outputs = predictions)
    
    # compile full model
    full_model.compile(loss='binary_crossentropy',
                  optimizer=keras.optimizers.Adamax(learning_rate=0.001),
                  metrics=['acc'])
    print(f'{model_key} training...')
    # model training
    history = full_model.fit(
    train_set, 
    validation_data = val_set,
    workers=2,
    epochs=30,
    )
    
    # model saveing
    #full_model.save(f'Saved_Models/{model_key}_10_epochs.h5')
    print(f'{model_key} is saving')
    # save model loss and accuracy graphs
    acc = history.history['acc']
    val_acc = history.history['val_acc']
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    plt.plot(acc)
    plt.plot(val_acc)
    plt.title(f'Training and validation accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.ylim()
    resolution_value = 1200
    plt.savefig(f'{model_key}_accuracy_10_epochs.png',format="png", dpi=resolution_value)

    plt.figure()
    plt.plot(loss)
    plt.plot(val_loss)
    plt.title(f'Training and validation loss {model_key}')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.savefig(f'{model_key}_loss_10_epochs.png',format="png", dpi=resolution_value)
    
    # uploading and notebook and model graphs to jovian plateform
    hyperparams = {
    'arch_name': model_key,
    'lr': .001
    }
    jovian.log_hyperparams(hyperparams)

    metrics = {
        'epoch': 10,
        'train_loss': history.history['loss'][-1],
        'val_loss': history.history['val_loss'][-1],
        'Train_acc': history.history['acc'][-1],
        'val_acc': history.history['val_acc'][-1]
    }
    jovian.commit(project=model_key,outputs=[f'{model_key}_loss_10_epochs.png',f'{model_key}_accuracy_10_epochs.png'])
    print(f'{model_key} is done')
    print("----------------------------------")


# In[ ]:


for model_key in pretrained_models.keys():
    conv_model = pretrained_models[f'{model_key}']
    
    # Freezing parameters of features eaxtractor
    conv_model.trainable = False
    
    # flatten the output of the convolutional part:
    x = keras.layers.Flatten()(conv_model.output)

    # three hidden layers
#     x = keras.layers.Dense(100, activation='relu')(x)
#     x1 = x
#     x = keras.layers.Dense(100, activation='relu')(x)
#     x2 = keras.layers.Dense(100)(x)
#     x3 = keras.layers.Add()([x1,x2])
    
#     x4 = keras.activations.relu(x3)
#     x = keras.layers.Dense(50, activation = 'relu')(x4)

    # final softmax layer with 25 categories 
    predictions = keras.layers.Dense(25, activation = 'softmax')(x)

    # creating the full model
    full_model = keras.models.Model(inputs = conv_model.input, outputs = predictions)
    
    # compile full model
    full_model.compile(loss='binary_crossentropy',
                  optimizer=keras.optimizers.Adamax(learning_rate=0.001),
                  metrics=['acc'])
    print(f'{model_key} is training...')
    # model training
    history = full_model.fit(
    train_set, 
    validation_data = val_set,
    workers=2,
    epochs=30,
    )
    
    # model saveing
#     full_model.save(f'Saved_Models/{model_key}_10_epochs.h5')
    print({model_key} is saving')
    # save model loss and accuracy graphs
    acc = history.history['acc']
    val_acc = history.history['val_acc']
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    plt.plot(acc)
    plt.plot(val_acc)
    plt.title(f'Training and validation accuracy {model_key}')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.ylim()
    resolution_value = 1200
    plt.savefig(f'{model_key}_accuracy_10_epochs.png',format="png", dpi=resolution_value)

    plt.figure()
    plt.plot(loss)
    plt.plot(val_loss)
    plt.title(f'Training and validation loss {model_key}')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.savefig(f'{model_key}_loss_10_epochs.png',format="png", dpi=resolution_value)
    
    # uploading and notebook and model graphs to jovian plateform
    hyperparams = {
    'arch_name': model_key,
    'lr': .001
    }
    jovian.log_hyperparams(hyperparams)

    metrics = {
        'epoch': 10,
        'val_loss': history.history['val_loss'][-1],
        'test_loss': history.history['val_loss'][-1],
        'val_acc': history.history['val_acc'][-1]
        'test_acc': history.history['val_acc'][-1]
    }
    jovian.log_metrics(metrics)
    jovian.commit(project=model_key,outputs=[f'{model_key}_loss_10_epochs.png',f'{model_key}_accuracy_10_epochs.png'])
    print({model_key} is done')
    print("----------------------------------")


# In[ ]:


scores = Malware_model.evaluate(X_test, y_test)
print('Final CNN accuracy: ', scores[1])


# In[ ]:




